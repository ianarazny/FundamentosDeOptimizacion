# -*- coding: utf-8 -*-
"""Copia de Obligatorio 1 - FuO 2023

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q5KrTTUDly-cz02NCBGRUZozQbOv1s70

# Obligatorio 1
Octavio Aguiar e Ian Arazny
"""

import numpy as np
import numpy.linalg as la
import numpy.random as rnd

# seteamos la semilla de generación de números aleatorios para reproducir los resultados
rnd.seed(2023)

m= 20
n= 10
A = rnd.rand(m,n)
b = rnd.rand(m)

"""Considere la función $f:\mathbb{R}^n \to \mathbb{R}$ definida como $f(x) = \frac{1}{2}||Ax-b||_2^2$, donde $A \in \mathbb{R}^{m\times n}$ es una matriz, y $b \in \mathbb{R}^m$ un vector dado. 



1.   Calcule el gradiente de la función ($\nabla{f}$). Escriba la expresión en esta celda de texto, y en la función de la celda de código siguiente.

$\nabla f(x) = 
A^T (Ax-b)$


"""

def f(x):
  return 0.5*la.norm(A@x-b)**2

def gradf(x):
  trans = A.T;
  return trans@((A@x)-b);

"""

2.   Compruebe numéricamente que el cálculo del gradiente es correcto, escribiendo una función que calcule una aproximación numérica del gradiente, a partir de cocientes incrementales.

"""

def grad_numerico(x):
  eps = 1e-7
  grad = np.zeros(n)
  h = np.zeros(n);
  for i in range(0,n):
    h[i] = eps;
    grad[i] = ((f(x+h)- f(x)) / eps);
    h[i] = 0;
  return grad

xr = rnd.rand(n)

#calculemos la norma de la diferencia entre el gradiente calculado y la aproximación numérica.
#Si todo está bien, debería ser un número chico
print(la.norm(gradf(xr) - grad_numerico(xr)))

"""3.  A partir de la expresión de $\nabla f$ hallada en el punto 1, escriba la condición de optimalidad, y halle un $x^*$ que la cumpla.

La condición de optimalidad es:
f es diferenciable en el punto $x^*$, $x^*$ un mínimo relativo, se cumple que  $|A*A^{T}| \neq 0$ y $x^* =(A^{T}*A)^{-1}*A^{T}*b$
"""

# sustituya 0 por el vector hallado que cumpla la condición de optimalidad
xstar = la.inv(A.T@A)@A.T@b;

"""4. Compruebe que el gradiente se anula en $x^*$"""

# En esta celda, comprobar la condición necesaria de optimalidad en xstar
print(np.allclose(gradf(xstar),np.zeros(n)));
# Todos los valores de la celda son aproximados a 0 (Da true)